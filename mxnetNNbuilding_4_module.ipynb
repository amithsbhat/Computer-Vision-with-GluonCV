{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5074b9d54a7c4c8dae2324b8cb78e503",
     "grade": false,
     "grade_id": "cell-fc0b22c123cbdd06",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Module 4 Assignment\n",
    "\n",
    "In this assignment, you'll use some of the key concepts from the module to create a neural network for image classification of items of clothing. Step one will be to normalize the input images, and you'll use NDArray operations to calculate the channel mean. You'll create a function to evaluate the performance of networks on the data, and construct a couple of different neural networks for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2bccf9794a4c9efd92100928a3f022e",
     "grade": false,
     "grade_id": "cell-abb560c26ec49a12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 0) Setup\n",
    "\n",
    "We start with a number of required imports and set the data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e397a0e3a9f2b4ad956a4b67efb70529",
     "grade": false,
     "grade_id": "cell-f6bddc494c867188",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from mxnet.gluon.data.vision import FashionMNIST\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "340f681667b511ce348ad946ab4617c9",
     "grade": false,
     "grade_id": "cell-5f7e8a74007e1017",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "M4_DATA = Path(os.getenv('DATA_DIR', '../../data'), 'module_4')\n",
    "M4_IMAGES = Path(M4_DATA, 'images')\n",
    "M4_MODELS = Path(M4_DATA, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb710ee3e61851413d0efa8fa50e44b5",
     "grade": false,
     "grade_id": "cell-95f0a503b6239c30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1) Data (& NDArray Operations)\n",
    "\n",
    "We'll use the in-built dataset called `FashionMNIST` which is a variant of the commonly used `MNIST` dataset. It consists of 60,000 training images and 10,000 test images, and each image is a 28px by 28px greyscale image. We'll start by creating the `dataset` and visualize an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ed040aeb4a6597a4b1b6732e5ea1758",
     "grade": false,
     "grade_id": "cell-ddb747acaf729e37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = FashionMNIST(train=False, root=M4_IMAGES).transform_first(transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9c9765da20>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = 123\n",
    "sample_data, sample_label = test_dataset[sample_idx]\n",
    "plt.imshow(sample_data[0].asnumpy())  # 0 for first and only channel (since greyscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed2ca106a69f67ee2e77786e0a54f4c8",
     "grade": false,
     "grade_id": "cell-cdac79c9b0e7354e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "One important step before passing images to the network is normalization: i.e. shifting and scaling the pixel values so that they are zero-centered on average and have unit variance.\n",
    "\n",
    "One method of normalization is pixelwise, where each **pixel** should have a unit normal distribution of values. Another is channelwise, where each **channel** should have a unit normal distribution of values. \n",
    "\n",
    "One of the first steps in the pixelwise approach is to calculate an 'average image' from the dataset. Using a sample of 1024 images, you should now implement a function to calculate the average intensity for every pixel. You'd typically want to calculate this from all samples of the dataset, but 1024 samples will be sufficient for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = mx.gluon.data.DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "for data, label in test_dataloader:\n",
    "    break\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[[0.         0.         0.         0.         0.         0.\n",
       "    0.         0.03529412 0.03137255 0.         0.         0.13333334\n",
       "    0.11372549 0.02745098 0.         0.04313726 0.09411765 0.\n",
       "    0.         0.01176471 0.01176471 0.00392157 0.         0.00392157\n",
       "    0.00392157 0.         0.         0.        ]\n",
       "   [0.         0.         0.01568628 0.         0.         0.00392157\n",
       "    0.         0.         0.         0.         0.         0.17254902\n",
       "    0.34509805 0.3882353  0.47843137 0.48235294 0.3137255  0.\n",
       "    0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.00392157 0.00784314 0.         0.\n",
       "    0.         0.01176471 0.18039216 0.68235296 0.9764706  0.2627451\n",
       "    0.         0.36862746 0.8235294  0.23921569 0.05490196 0.83137256\n",
       "    0.6156863  0.14509805 0.         0.         0.         0.\n",
       "    0.00392157 0.         0.         0.        ]\n",
       "   [0.         0.         0.00784314 0.00784314 0.         0.09019608\n",
       "    0.65882355 0.80784315 0.9490196  0.9372549  0.93333334 0.8392157\n",
       "    0.49019608 0.23921569 0.44313726 0.2901961  0.52156866 0.9254902\n",
       "    0.93333334 0.9254902  0.79607844 0.72156864 0.07843138 0.\n",
       "    0.00392157 0.         0.         0.        ]\n",
       "   [0.         0.         0.00392157 0.         0.         0.6862745\n",
       "    0.9607843  0.8745098  0.8117647  0.8039216  0.80784315 0.84705883\n",
       "    1.         0.92941177 0.9843137  0.9098039  0.8745098  0.83137256\n",
       "    0.78431374 0.8039216  0.84705883 0.9764706  0.6784314  0.\n",
       "    0.         0.00784314 0.         0.        ]\n",
       "   [0.         0.         0.02745098 0.         0.20784314 0.88235295\n",
       "    0.7882353  0.77254903 0.78431374 0.7882353  0.80784315 0.78039217\n",
       "    0.77254903 0.7254902  0.7607843  0.8        0.9098039  0.8862745\n",
       "    0.9764706  0.85882354 0.7607843  0.8039216  0.8980392  0.12941177\n",
       "    0.         0.00392157 0.         0.        ]\n",
       "   [0.         0.         0.00392157 0.         0.52156866 0.8745098\n",
       "    0.8156863  0.7529412  0.7647059  0.9137255  0.8862745  0.84705883\n",
       "    0.7490196  0.8235294  0.7372549  0.9254902  0.7294118  0.\n",
       "    0.19607843 0.91764706 0.8117647  0.8156863  0.90588236 0.52156866\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.84705883 0.85490197\n",
       "    0.84705883 0.7607843  0.8980392  0.6745098  0.2509804  0.85882354\n",
       "    0.7882353  0.78431374 0.78431374 0.96862745 0.26666668 0.28235295\n",
       "    0.21176471 0.64705884 0.92941177 0.83137256 0.85882354 0.8862745\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.19607843 0.8666667  0.8117647\n",
       "    0.8627451  0.827451   0.8117647  0.64705884 0.5411765  0.8039216\n",
       "    0.7529412  0.7490196  0.74509805 0.9098039  0.46666667 0.44313726\n",
       "    0.2627451  0.6784314  0.92941177 0.8509804  0.8156863  0.8666667\n",
       "    0.11372549 0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.5137255  0.84705883 0.78431374\n",
       "    0.85882354 0.8117647  0.83137256 0.90588236 0.8862745  0.75686276\n",
       "    0.8392157  0.8784314  0.80784315 0.79607844 0.9019608  0.47843137\n",
       "    0.4392157  0.91764706 0.8784314  0.8392157  0.8        0.8784314\n",
       "    0.48235294 0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.7647059  0.83137256 0.8\n",
       "    0.827451   0.79607844 0.8039216  0.78431374 0.72156864 0.8352941\n",
       "    0.63529414 0.5411765  0.75686276 0.8117647  0.79607844 0.90588236\n",
       "    0.9607843  0.8156863  0.8627451  0.827451   0.79607844 0.85882354\n",
       "    0.7019608  0.         0.         0.        ]\n",
       "   [0.         0.         0.03137255 0.7254902  0.7490196  0.85490197\n",
       "    0.9137255  0.85882354 0.7882353  0.8666667  0.8352941  0.9647059\n",
       "    0.44705883 0.49803922 0.3137255  0.5058824  0.9098039  0.7764706\n",
       "    0.85490197 0.8117647  0.9254902  0.8901961  0.8627451  0.84705883\n",
       "    0.6745098  0.08235294 0.         0.        ]\n",
       "   [0.         0.         0.08235294 0.01568628 0.01960784 0.2509804\n",
       "    0.627451   0.8784314  0.8784314  0.5647059  0.73333335 0.77254903\n",
       "    0.827451   0.8117647  0.7294118  0.7529412  0.8235294  0.83137256\n",
       "    0.85490197 0.88235295 0.9254902  0.69411767 0.41568628 0.21960784\n",
       "    0.10980392 0.00392157 0.         0.        ]\n",
       "   [0.         0.         0.00392157 0.00392157 0.         0.00784314\n",
       "    0.         0.45490196 0.9882353  0.3764706  0.47058824 0.2\n",
       "    0.28627452 0.27450982 0.48235294 0.30980393 0.29803923 0.2509804\n",
       "    0.63529414 0.9882353  0.4627451  0.00392157 0.01176471 0.\n",
       "    0.01568628 0.00784314 0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.         0.\n",
       "    0.         0.4509804  0.8862745  0.5686275  0.6666667  0.60784316\n",
       "    0.64705884 0.6313726  0.62352943 0.49019608 0.6862745  0.54901963\n",
       "    0.68235296 0.9254902  0.37254903 0.         0.00784314 0.00784314\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.00392157 0.00784314\n",
       "    0.         0.5137255  0.88235295 0.8        0.8509804  0.8666667\n",
       "    0.8627451  0.8509804  0.8784314  0.90588236 0.8862745  0.92941177\n",
       "    0.79607844 0.92941177 0.4        0.         0.01568628 0.00784314\n",
       "    0.00392157 0.00784314 0.         0.        ]\n",
       "   [0.         0.         0.00392157 0.00392157 0.         0.01176471\n",
       "    0.         0.5294118  0.8745098  0.7882353  0.78039217 0.7607843\n",
       "    0.7764706  0.7647059  0.7764706  0.7529412  0.79607844 0.78039217\n",
       "    0.8117647  0.90588236 0.4392157  0.         0.01568628 0.\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.00392157 0.00392157 0.         0.00392157\n",
       "    0.         0.5254902  0.8745098  0.78039217 0.80784315 0.78039217\n",
       "    0.7882353  0.78431374 0.79607844 0.80784315 0.8117647  0.8235294\n",
       "    0.80784315 0.8901961  0.46666667 0.         0.01176471 0.\n",
       "    0.         0.00392157 0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.         0.00392157\n",
       "    0.         0.54509807 0.8745098  0.7764706  0.8        0.78431374\n",
       "    0.7882353  0.78431374 0.7882353  0.8        0.80784315 0.8156863\n",
       "    0.80784315 0.8980392  0.5019608  0.         0.01568628 0.\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.         0.00392157\n",
       "    0.         0.5686275  0.8745098  0.7647059  0.8039216  0.7882353\n",
       "    0.7882353  0.78431374 0.8        0.8        0.80784315 0.827451\n",
       "    0.8039216  0.9019608  0.54509807 0.         0.00784314 0.\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.00392157 0.         0.00392157 0.\n",
       "    0.         0.6156863  0.8666667  0.7607843  0.8        0.8\n",
       "    0.7882353  0.7882353  0.79607844 0.8039216  0.8156863  0.827451\n",
       "    0.8        0.9019608  0.5803922  0.         0.00784314 0.\n",
       "    0.00392157 0.00392157 0.         0.        ]\n",
       "   [0.         0.         0.00392157 0.00392157 0.00392157 0.\n",
       "    0.         0.6509804  0.8627451  0.7607843  0.79607844 0.79607844\n",
       "    0.8039216  0.79607844 0.79607844 0.80784315 0.8117647  0.83137256\n",
       "    0.8        0.9019608  0.6156863  0.         0.00784314 0.00392157\n",
       "    0.00392157 0.00392157 0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.         0.\n",
       "    0.         0.67058825 0.8666667  0.7647059  0.80784315 0.78431374\n",
       "    0.78039217 0.79607844 0.79607844 0.8039216  0.80784315 0.8117647\n",
       "    0.8        0.8862745  0.70980394 0.         0.         0.\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.00392157 0.\n",
       "    0.         0.64705884 0.8784314  0.77254903 0.7882353  0.8156863\n",
       "    0.78039217 0.8        0.8039216  0.8117647  0.8235294  0.8352941\n",
       "    0.8117647  0.8980392  0.73333335 0.         0.00392157 0.00784314\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.         0.\n",
       "    0.         0.5019608  0.7882353  0.79607844 0.7882353  0.8117647\n",
       "    0.827451   0.79607844 0.8039216  0.80784315 0.8235294  0.8352941\n",
       "    0.8039216  0.88235295 0.7490196  0.         0.         0.00784314\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.00392157 0.00392157\n",
       "    0.         0.5529412  0.7882353  0.7490196  0.7372549  0.7607843\n",
       "    0.73333335 0.73333335 0.7490196  0.75686276 0.7647059  0.78039217\n",
       "    0.78039217 0.85490197 0.6313726  0.         0.         0.\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.         0.00392157\n",
       "    0.         0.83137256 0.9411765  0.8352941  0.9372549  0.9137255\n",
       "    0.9372549  0.90588236 0.9098039  0.9254902  0.9490196  0.9607843\n",
       "    0.8784314  0.9607843  0.91764706 0.         0.01176471 0.\n",
       "    0.         0.         0.         0.        ]\n",
       "   [0.         0.         0.         0.         0.         0.\n",
       "    0.         0.14509805 0.27058825 0.36862746 0.48235294 0.49803922\n",
       "    0.5411765  0.5411765  0.5568628  0.5686275  0.5294118  0.49019608\n",
       "    0.40392157 0.34117648 0.21960784 0.         0.         0.\n",
       "    0.         0.         0.         0.        ]]]\n",
       " <NDArray 1x28x28 @cpu(0)>, (1, 28, 28))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0], data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "028925a530e2ed4d602226963e5e3409",
     "grade": false,
     "grade_id": "cell-c347c7c9342cbeb1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_average_image_from_batch(batch):\n",
    "    \"\"\"\n",
    "    Given a batch of images, this function should calculate the 'average image'.\n",
    "    \n",
    "    :param batch: batch of images in NCHW layout.\n",
    "    :type batch: mx.nd.NDArray\n",
    "    \n",
    "    :return: average image in CHW layout.\n",
    "    :rtype: mx.nd.NDArray\n",
    "    \"\"\"\n",
    "    return( mx.nd.mean(batch, axis=0)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7afa5949415bf47373e5760b8df699c3",
     "grade": true,
     "grade_id": "cell-1b3d8700f95a0e26",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9c9771a0b8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_image = get_average_image_from_batch(data)\n",
    "assert average_image.shape == (1, 28, 28)\n",
    "plt.imshow(average_image[0].asnumpy())  # 0 for first and only channel (since greyscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c60c3d88653d4d13ddfc97a891d2041",
     "grade": false,
     "grade_id": "cell-8289081a2395a032",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using the average image that was calculated above, you should now implement a function to perform the pixelwise normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "237357a2b5ce96f61e37e68a000aae79",
     "grade": false,
     "grade_id": "cell-970eddb5f76be1f0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def subtract_average_image(sample, average_image):\n",
    "    \"\"\"\n",
    "    Given a sample images, this function should return a pixelwise normalized image,\n",
    "    using a pre-calculated average image.\n",
    "    \n",
    "    :param sample: sample image in CHW layout.\n",
    "    :type sample: mx.nd.NDArray\n",
    "    :param average_image: average image of the dataset in CHW layout.\n",
    "    :type average_image: mx.nd.NDArray\n",
    "    \n",
    "    :return: pixelwise normalized image in CHW layout.\n",
    "    :rtype: mx.nd.NDArray\n",
    "    \"\"\"\n",
    "    \n",
    "    return sample - average_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93a9e45c83be15ffd405137234e41c24",
     "grade": true,
     "grade_id": "cell-4f8cfd20e9027638",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9cb1fc5e48>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_sample_data = subtract_average_image(sample_data, average_image)\n",
    "assert normalized_sample_data.shape == (1, 28, 28)\n",
    "np.testing.assert_array_almost_equal(normalized_sample_data.asnumpy(), (sample_data - average_image).asnumpy())\n",
    "plt.imshow(normalized_sample_data[0].asnumpy())  # 0 for first and only channel (since greyscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've now created a transform for pixelwise normalization! As mentioned previously, another common method for normalization is channelwise normalization. Complete the following function to calculate the channel averages from a batch of multi-channel inputs.\n",
    "\n",
    "Note: although the image from our dataset only have one channel, your function should support cases where there are more than one channel (e.g. RGB images).\n",
    "\n",
    "**Hint**: Check out the `axis` (or `dim`) arguments on MXNet NDArray functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a20aa5394fbb2a4d50af68667ed995c6",
     "grade": false,
     "grade_id": "cell-d2bd82c63c0c28c9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_channel_average_from_batch(batch):\n",
    "    \"\"\"\n",
    "    Given a batch of images, this function should return the\n",
    "    average value for each channel across the images of the batch.\n",
    "    \n",
    "    :param batch: batch of images in NCHW layout.\n",
    "    :type batch: mx.nd.NDArray\n",
    "    \n",
    "    :return: channel averages in C layout.\n",
    "    :rtype: mx.nd.NDArray\n",
    "    \"\"\"\n",
    "    return( mx.nd.mean(batch, axis=1, exclude=True)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61ce9104b23fdb0b51a498914c9375b3",
     "grade": true,
     "grade_id": "cell-1132428ff435fdff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28757906\n"
     ]
    }
   ],
   "source": [
    "channel_average = get_channel_average_from_batch(data).asscalar()\n",
    "print(channel_average)\n",
    "assert isinstance(channel_average, np.float32)\n",
    "np.testing.assert_almost_equal(channel_average, 0.28757906, decimal=5)\n",
    "\n",
    "test_averages = mx.nd.array([1,2,3,4])\n",
    "test_input = mx.nd.reshape(test_averages, shape=(1,4,1,1)) * mx.nd.ones(shape=(10,4,25,25))\n",
    "test_channel_average = get_channel_average_from_batch(test_input)\n",
    "np.testing.assert_array_almost_equal(test_averages.asnumpy(), test_channel_average.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebf52b1649339c3bc81609fd7d8eb8a6",
     "grade": false,
     "grade_id": "cell-2fea1fe63abd02d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using this channel average, we can use the `Normalize` transform to apply this to all samples in our dataset as they are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c8c7678fffe3316b1d26df20948d9d3",
     "grade": false,
     "grade_id": "cell-1406cf76c0bf2d9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "channel_std = 0.31\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(channel_average, channel_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "997486e117bb21d91c6c6d2e1793d5e1",
     "grade": false,
     "grade_id": "cell-09b598f5df48310e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(train=True, root=M4_IMAGES).transform_first(transform)\n",
    "test_dataset = FashionMNIST(train=False, root=M4_IMAGES).transform_first(transform)\n",
    "train_dataloader = mx.gluon.data.DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
    "test_dataloader = mx.gluon.data.DataLoader(train_dataset, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Metrics\n",
    "\n",
    "In this section, you'll implement a function to test the prediction quality of networks. Using `Accuracy` as the evaluation metric, complete the following function that takes a network and a dataloader (with test data) and returns an MXNet Metric that has been updated with labels and predictions. We'll use this function in the next section, when we train classification networks.\n",
    "\n",
    "**Hint**: You'll find classes in the `mxnet.metric` subpackage useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "648cf62a617935ea6d929c14af92eb8b",
     "grade": false,
     "grade_id": "cell-5fab64bc4b4aa8dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import metric\n",
    "\n",
    "def calculate_accuracy(network, dataloader):\n",
    "    \"\"\"\n",
    "    Calculates accuracy of the network on the data given by the dataloader.\n",
    "    \n",
    "    :param network: network to be tested\n",
    "    :type network: mx.gluon.Block\n",
    "    :param dataloader: dataloader for test data\n",
    "    :type dataloader: mx.gluon.data.DataLoader\n",
    "    \n",
    "    :return: updated metric\n",
    "    :rtype: mx.metric.EvalMetric\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = metric.Accuracy()\n",
    "    for data, labels in tqdm(dataloader):\n",
    "        preds = network(data)\n",
    "        accuracy.update(labels= labels, preds = preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a5f1bac4bcf9a3e81d52ea269a61070",
     "grade": true,
     "grade_id": "cell-56296ecc0573751e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:43<00:00, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.08005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_network = mx.gluon.nn.Dense(units=10)\n",
    "test_network.initialize()\n",
    "metric = calculate_accuracy(test_network, test_dataloader)\n",
    "print(metric.get())\n",
    "isinstance(metric, mx.metric.EvalMetric)\n",
    "assert metric.name == 'accuracy'\n",
    "assert metric.num_inst == 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb82044f0fc5c506b7e0ded91ed9b428",
     "grade": false,
     "grade_id": "cell-3f04789a1e05233e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3) Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section, you'll implement a couple of different image classification networks and train then on the `FashionMNIST` dataset. A `train` function is already provided in this assignment, because the focus will be on network construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77f5bee4daf2e646e8b00a4cb792c9ab",
     "grade": false,
     "grade_id": "cell-027a252196f10f5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train(network, dataloader):\n",
    "    softmax_cross_entropy = mx.gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    trainer = mx.gluon.Trainer(network.collect_params(), 'sgd', {'learning_rate': 0.1})\n",
    "    for data, label in tqdm(dataloader):\n",
    "        with mx.autograd.record():\n",
    "            output = network(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d078ccad213eb7f0540c0e0a7f4fd6f",
     "grade": false,
     "grade_id": "cell-8835b94cce73c05b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Your first model should be a sequential network, with 3 layers. You first layer should have 16 hidden units, the second should have 8 hidden units and the last layer should the correct number of output units for the classification task at hand. You should add ReLU activations on all hidden layers, but not the output layer. You should define `network` in the cell below.\n",
    "\n",
    "**Hint**: You'll find classes in the `mxnet.gluon.nn` subpackage useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d35d987cac115ee0c6fcde1ccf9395ab",
     "grade": false,
     "grade_id": "cell-60d2aed0c10748dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn \n",
    "network = nn.Sequential()\n",
    "network.add(\n",
    "nn.Dense(16, activation = 'relu'),\n",
    "nn.Dense(8,activation ='relu'),\n",
    "nn.Dense(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bac44090ed660601c9bb11488e4457e8",
     "grade": true,
     "grade_id": "cell-fab27ff9cbdb32f3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(network, mx.gluon.nn.Sequential)\n",
    "assert len(network) == 3\n",
    "assert isinstance(network[0], mx.gluon.nn.Dense)\n",
    "assert network[0].act.name.endswith('relu')\n",
    "assert network[0].weight.shape[0] == 16\n",
    "assert isinstance(network[1], mx.gluon.nn.Dense)\n",
    "assert network[1].act.name.endswith('relu')\n",
    "assert network[1].weight.shape[0] == 8\n",
    "assert isinstance(network[2], mx.gluon.nn.Dense)\n",
    "assert network[2].act is None\n",
    "assert network[2].weight.shape[0] == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a12fc8925d662b2379c9da051c6ad04d",
     "grade": false,
     "grade_id": "cell-0c105c466260d8df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With your network now defined, you should initialize its parameters using the Xavier method in the cell below.\n",
    "\n",
    "**Hint**: You'll find classes in the `mxnet.init` subpackage useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5034e223765daeb8ff11357a8385621d",
     "grade": false,
     "grade_id": "cell-fa9e3830a921ccc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "initializer = mx.init.Xavier()\n",
    "network.initialize(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "082079014c9879392a59ea4f9ba69b89",
     "grade": true,
     "grade_id": "cell-aab6f8ac1595ddf3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(initializer, mx.initializer.Xavier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b66a83fe4f502980f1aa332babea54a",
     "grade": false,
     "grade_id": "cell-71470ca5057ba4e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll now check the network summary and see that the network has 12786 trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59aea017252d590b7e5f1d59e4997cf6",
     "grade": false,
     "grade_id": "cell-a13e4f389f395b25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                           (1024, 1, 28, 28)               0\n",
      "        Activation-1                    <Symbol dense1_relu_fwd>               0\n",
      "        Activation-2                                  (1024, 16)               0\n",
      "             Dense-3                                  (1024, 16)           12560\n",
      "        Activation-4                    <Symbol dense2_relu_fwd>               0\n",
      "        Activation-5                                   (1024, 8)               0\n",
      "             Dense-6                                   (1024, 8)             136\n",
      "             Dense-7                                  (1024, 10)              90\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 12786\n",
      "   Trainable params: 12786\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 12786\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "network.summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5770042162ac6a34dfd0eb57cef562a",
     "grade": false,
     "grade_id": "cell-f23f24b41797c698",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And use the `calculate_accuracy` function defined in the previous section to evaluate the performance of this architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "958cb52f6fea4c610ad6fb12b69c9cd6",
     "grade": false,
     "grade_id": "cell-15085d2bbec07611",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [00:46<00:00, 10.06it/s]\n",
      "100%|| 469/469 [00:35<00:00, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.8400333333333333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(network, train_dataloader)\n",
    "metric = calculate_accuracy(network, test_dataloader)\n",
    "print(metric.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aae608960225ca66817116e7e18a9247",
     "grade": false,
     "grade_id": "cell-b4bb794993da124b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You're final objective in this assignment is to try a different architecture that uses convolutional and max pooling layers. You should define another sequential network, but this time it should have 5 layers in total:\n",
    "\n",
    "1. Convolutional Layer (32 channels, 3x3 kernel and ReLU activation)\n",
    "2. Max Pooling Layer (2x2 kernel and 2x2 stride)\n",
    "3. Convolutional Layer (16 channels, 3x3 kernel and ReLU activation)\n",
    "4. Max Pooling Layer (2x2 kernel and 2x2 stride)\n",
    "5. Dense Layer (10 output units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2da3d4d690016aa9b1fddafe7c9f4c5",
     "grade": false,
     "grade_id": "cell-27362e76af20b586",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "network = nn.Sequential()\n",
    "network.add(\n",
    "nn.Conv2D(32, (3,3), activation = 'relu'),\n",
    "nn.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "nn.Conv2D(16, (3,3), activation = 'relu'),\n",
    "nn.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "nn.Dense(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "658f43b3f172cefd8a416f9143c0cc9a",
     "grade": true,
     "grade_id": "cell-f6d99cca56b03a4c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(network, mx.gluon.nn.Sequential)\n",
    "assert len(network) == 5\n",
    "assert isinstance(network[0], mx.gluon.nn.Conv2D)\n",
    "assert network[0].act.name.endswith('relu')\n",
    "assert network[0].weight.shape[0] == 32\n",
    "assert isinstance(network[1], mx.gluon.nn.MaxPool2D)\n",
    "assert isinstance(network[2], mx.gluon.nn.Conv2D)\n",
    "assert network[2].act.name.endswith('relu')\n",
    "assert network[2].weight.shape[0] == 16\n",
    "assert isinstance(network[3], mx.gluon.nn.MaxPool2D)\n",
    "assert isinstance(network[4], mx.gluon.nn.Dense)\n",
    "assert network[4].act is None\n",
    "assert network[4].weight.shape[0] == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59680071ae46fddcb37e07b965fc9dbc",
     "grade": false,
     "grade_id": "cell-7aba8aa6bd98797e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's initialize the parameters of the network, and show a summary of the network architecture.\n",
    "\n",
    "With 8954 trainable parameters, this network's got 30% fewer parameters than the previous network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "226a74a762a411b9a6ec985a7b3b4d02",
     "grade": false,
     "grade_id": "cell-5b9ad1023c066bbe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                           (1024, 1, 28, 28)               0\n",
      "        Activation-1                     <Symbol conv0_relu_fwd>               0\n",
      "        Activation-2                          (1024, 32, 26, 26)               0\n",
      "            Conv2D-3                          (1024, 32, 26, 26)             320\n",
      "         MaxPool2D-4                          (1024, 32, 13, 13)               0\n",
      "        Activation-5                     <Symbol conv1_relu_fwd>               0\n",
      "        Activation-6                          (1024, 16, 11, 11)               0\n",
      "            Conv2D-7                          (1024, 16, 11, 11)            4624\n",
      "         MaxPool2D-8                            (1024, 16, 5, 5)               0\n",
      "             Dense-9                                  (1024, 10)            4010\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 8954\n",
      "   Trainable params: 8954\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 8954\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "network.initialize(init=initializer)\n",
    "network.summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c93f40630de025d96f78ca5df6f8b0a",
     "grade": false,
     "grade_id": "cell-3b2f9d639c371864",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And finally, let's evaluate the network performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "797450f201e5b58137770b5afbcdde27",
     "grade": false,
     "grade_id": "cell-6a0bbef7dab7fc86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 469/469 [02:30<00:00,  2.89it/s]\n",
      "100%|| 469/469 [04:09<00:00,  4.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.8697666666666667)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(network, train_dataloader)\n",
    "metric = calculate_accuracy(network, test_dataloader)\n",
    "print(metric.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "daac204b6befa96b9d1ceb3883b7dffb",
     "grade": false,
     "grade_id": "cell-9a3e6f798eaeb49b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We're only training for a single epoch here. You'd expect to get improved accuracy if training for more epochs. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "assignment_name": "module_4",
   "assignment_version": 2,
   "course_slug": "aws-computer-vision-gluoncv",
   "graded_item_id": "FoZrl",
   "launcher_item_id": "vcm0m"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
